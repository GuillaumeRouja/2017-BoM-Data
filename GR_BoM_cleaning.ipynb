{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using BoM data to present 2017 hourly information on temperatures and precipitations ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 : Importing the libraries and functions saved in a py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import datetime \n",
    "import math \n",
    "import time\n",
    "\n",
    "from Weather_functions import Datastations\n",
    "from Weather_functions import Datagap\n",
    "from Weather_functions import Datafilling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2 : Uploading data from the weather stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "station number? 68241\n",
      "33519\n",
      "   station_number  area_code parameter  valid_start   valid_end  value  \\\n",
      "0           68241  NSW_PT001      MaxT   1493596800  1493600400   22.1   \n",
      "1           68241  NSW_PT001      MaxT   1493600400  1493604000   23.5   \n",
      "2           68241  NSW_PT001      MaxT   1493604000  1493607600   24.1   \n",
      "3           68241  NSW_PT001      MaxT   1493607600  1493611200   24.7   \n",
      "4           68241  NSW_PT001      MaxT   1493611200  1493614800   24.5   \n",
      "\n",
      "      unit statistic level  qc_valid_minutes  qc_valid_start  qc_valid_end  \n",
      "0  Celsius       max   SFC                60      1493596800    1493600400  \n",
      "1  Celsius       max   SFC                57      1493600400    1493604000  \n",
      "2  Celsius       max   SFC                60      1493604000    1493607600  \n",
      "3  Celsius       max   SFC                60      1493607600    1493611200  \n",
      "4  Celsius       max   SFC                60      1493611200    1493614800  \n",
      "35036\n",
      "   station_number  area_code parameter  valid_start   valid_end  value  \\\n",
      "0           68241  NSW_PT001  AIR_TEMP   1462024800  1462024800   13.3   \n",
      "1           68241  NSW_PT001  AIR_TEMP   1462028400  1462028400   13.1   \n",
      "2           68241  NSW_PT001  AIR_TEMP   1462032000  1462032000   12.6   \n",
      "3           68241  NSW_PT001  AIR_TEMP   1462035600  1462035600   12.8   \n",
      "4           68241  NSW_PT001  AIR_TEMP   1462039200  1462039200   13.7   \n",
      "\n",
      "      unit statistic  instantaneous level  qc_valid_minutes  \\\n",
      "0  Celsius     first           True   SFC               NaN   \n",
      "1  Celsius     first           True   SFC               NaN   \n",
      "2  Celsius     first           True   SFC               NaN   \n",
      "3  Celsius     first           True   SFC               NaN   \n",
      "4  Celsius     first           True   SFC               NaN   \n",
      "\n",
      "   qc_valid_minutes_start  qc_valid_minutes_end  \n",
      "0              1462024800                   NaN  \n",
      "1              1462028400                   NaN  \n",
      "2              1462032000                   NaN  \n",
      "3              1462035600                   NaN  \n",
      "4              1462039200                   NaN  \n",
      "--- 104.54542398452759 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time() #Check running time of data upload (i would like to improve that running time in the future)\n",
    "\n",
    "station = int(input(\"station number? \")) #68241 = Dapto\n",
    "\n",
    "df1 = Datastations(station,\"refdata/obs\") # Run function to extract and combine csv files for 2017/2018\n",
    "df2 = Datastations(station,\"refdata/BoM_ETA_20160501-20170430/obs\") # Run function to extract and combine csv files for 2016/2017\n",
    "\n",
    "print (len(df1)) \n",
    "print (df1.head()) \n",
    "print (len(df2)) \n",
    "print (df2.head()) \n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3 : Changing time format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-01T11:00:00.000000000 2017-05-01T12:00:00.000000000\n",
      "2016-05-01T01:00:00.000000000 2016-05-01T02:00:00.000000000\n"
     ]
    }
   ],
   "source": [
    "#for df1 \n",
    "\n",
    "df1[\"valid_start\"] = df1[\"valid_start\"].apply(pd.to_numeric)\n",
    "df1[\"valid_end\"] = df1[\"valid_end\"].apply(pd.to_numeric)\n",
    "\n",
    "df1[\"valid_start\"]= df1[\"valid_start\"]+36000 # add 10h to convert GMT to Australia time\n",
    "df1[\"valid_end\"]= df1[\"valid_end\"]+36000\n",
    "\n",
    "df1[\"valid_start\"] = pd.to_datetime(df1[\"valid_start\"],unit='s') # convert epoch time in valid time\n",
    "df1[\"valid_end\"] = pd.to_datetime(df1[\"valid_end\"],unit='s') \n",
    "\n",
    "print(df1['valid_start'].values[1],df1['valid_end'].values[1])\n",
    "\n",
    "#for df2\n",
    "\n",
    "df2[\"valid_start\"] = df2[\"valid_start\"].apply(pd.to_numeric)\n",
    "df2[\"valid_end\"] = df2[\"valid_end\"].apply(pd.to_numeric)\n",
    "\n",
    "df2[\"valid_start\"]= df2[\"valid_start\"]+36000 # add 10h to convert GMT to Australia time\n",
    "df2[\"valid_end\"]= df2[\"valid_end\"]+36000\n",
    "\n",
    "df2.loc[df2.parameter ==\"AIR_TEMP\", \"valid_end\"] = df2[\"valid_end\"]+3600 # add 1h to AIR_TEMP (appears as instantaneous)\n",
    "df2.loc[df2.parameter ==\"PRCP\", \"valid_end\"] = df2[\"valid_end\"]+3000 # Precip. are only reported on the first 10 min of each hour so add 50 min.\n",
    " \n",
    "df2[\"valid_start\"] = pd.to_datetime(df2[\"valid_start\"],unit='s') #convert epoch time in normal time\n",
    "df2[\"valid_end\"] = pd.to_datetime(df2[\"valid_end\"],unit='s') \n",
    "\n",
    "print(df2['valid_start'].values[1],df2['valid_end'].values[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 4 : Data cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8563\n",
      "          valid_start           valid_end  station_number T_Celsius  \\\n",
      "0 2017-05-01 10:00:00 2017-05-01 11:00:00           68241      20.8   \n",
      "1 2017-05-01 11:00:00 2017-05-01 12:00:00           68241      21.6   \n",
      "2 2017-05-01 12:00:00 2017-05-01 13:00:00           68241      23.5   \n",
      "3 2017-05-01 13:00:00 2017-05-01 14:00:00           68241      23.0   \n",
      "4 2017-05-01 14:00:00 2017-05-01 15:00:00           68241      24.1   \n",
      "\n",
      "  MinT_Celsius MaxT_Celsius Precip_mm  \n",
      "0         20.5         22.1       0.0  \n",
      "1         21.6         23.5       0.0  \n",
      "2         22.5         24.1       0.0  \n",
      "3         22.7         24.7       0.0  \n",
      "4         23.1         24.5       0.0  \n",
      "8759\n",
      "          valid_start           valid_end  station_number T_Celsius  \\\n",
      "0 2016-05-01 00:00:00 2016-05-01 01:00:00           68241      13.3   \n",
      "1 2016-05-01 01:00:00 2016-05-01 02:00:00           68241      13.1   \n",
      "2 2016-05-01 02:00:00 2016-05-01 03:00:00           68241      12.6   \n",
      "3 2016-05-01 03:00:00 2016-05-01 04:00:00           68241      12.8   \n",
      "4 2016-05-01 04:00:00 2016-05-01 05:00:00           68241      13.7   \n",
      "\n",
      "  MinT_Celsius MaxT_Celsius Precip_mm  \n",
      "0         13.1         14.4       0.0  \n",
      "1         12.7         13.2       0.0  \n",
      "2         12.1         13.1       0.0  \n",
      "3         12.6         13.6       0.0  \n",
      "4         13.2         14.6       0.0  \n"
     ]
    }
   ],
   "source": [
    "#for df1\n",
    "df1['T_Celsius'] = np.where(df1['parameter']=='T', df1['value'], '') # create new columns before dropping unncessary ones\n",
    "df1['MinT_Celsius'] = np.where(df1['parameter']=='MinT', df1['value'], '')\n",
    "df1['MaxT_Celsius'] = np.where(df1['parameter']=='MaxT', df1['value'], '')\n",
    "df1['Precip_mm'] = np.where(df1['parameter']=='Precip', df1['value'], '')\n",
    "\n",
    "df1= df1.drop([\"area_code\", \"unit\", \"statistic\", \"level\",\"qc_valid_minutes\",\"parameter\",\"value\",\"qc_valid_start\",\"qc_valid_end\"], axis=1) # drop unncessary columns \n",
    "df1 = df1.groupby(['valid_start','valid_end','station_number'])['T_Celsius','MinT_Celsius','MaxT_Celsius','Precip_mm'].sum().reset_index()\n",
    "\n",
    "print (len(df1)) #-> result should be close to (365*24=8760)\n",
    "print(df1.head())\n",
    "\n",
    "#for df2 ->repeat same steps \n",
    "\n",
    "df2['T_Celsius'] = np.where(df2['parameter']=='AIR_TEMP', df2['value'], '')\n",
    "df2['MinT_Celsius'] = np.where(df2['parameter']=='AIR_TEMP_MIN', df2['value'], '')\n",
    "df2['MaxT_Celsius'] = np.where(df2['parameter']=='AIR_TEMP_MAX', df2['value'], '')\n",
    "df2['Precip_mm'] = np.where(df2['parameter']=='PRCP', df2['value'], '')\n",
    "\n",
    "df2= df2.drop([\"area_code\", \"unit\", \"statistic\", \"level\",\"qc_valid_minutes\",\"parameter\",\"value\",\"instantaneous\",\"qc_valid_minutes_start\",\"qc_valid_minutes_end\"], axis=1) \n",
    "df2 = df2.groupby(['valid_start','valid_end','station_number'])['T_Celsius','MinT_Celsius','MaxT_Celsius','Precip_mm'].sum().reset_index()\n",
    "\n",
    "print (len(df2)) \n",
    "print(df2.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5 : Merging dataframes and checking missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17322\n",
      "             valid_start           valid_end  station_number T_Celsius  \\\n",
      "5880 2017-01-01 00:00:00 2017-01-01 01:00:00         68241.0      21.5   \n",
      "5881 2017-01-01 01:00:00 2017-01-01 02:00:00         68241.0      21.6   \n",
      "5882 2017-01-01 02:00:00 2017-01-01 03:00:00         68241.0      21.5   \n",
      "5883 2017-01-01 03:00:00 2017-01-01 04:00:00         68241.0      21.1   \n",
      "5884 2017-01-01 04:00:00 2017-01-01 05:00:00         68241.0      21.0   \n",
      "\n",
      "     MinT_Celsius MaxT_Celsius Precip_mm  \n",
      "5880         21.5         21.8       0.0  \n",
      "5881         21.4         21.6       0.0  \n",
      "5882         21.1         21.5       0.0  \n",
      "5883         20.9         21.2       0.2  \n",
      "5884         20.9         21.1       0.0  \n",
      "              valid_start valid_end  station_number T_Celsius MinT_Celsius  \\\n",
      "14635 2017-12-31 19:00:00       NaT             NaN       NaN          NaN   \n",
      "14636 2017-12-31 20:00:00       NaT             NaN       NaN          NaN   \n",
      "14637 2017-12-31 21:00:00       NaT             NaN       NaN          NaN   \n",
      "14638 2017-12-31 22:00:00       NaT             NaN       NaN          NaN   \n",
      "14639 2017-12-31 23:00:00       NaT             NaN       NaN          NaN   \n",
      "\n",
      "      MaxT_Celsius Precip_mm  \n",
      "14635          NaN       NaN  \n",
      "14636          NaN       NaN  \n",
      "14637          NaN       NaN  \n",
      "14638          NaN       NaN  \n",
      "14639          NaN       NaN  \n",
      "8760\n",
      "valid_start         0\n",
      "valid_end           0\n",
      "station_number      0\n",
      "T_Celsius         419\n",
      "MinT_Celsius      418\n",
      "MaxT_Celsius      418\n",
      "Precip_mm         174\n",
      "dtype: int64\n",
      "Warning datagap >= 5 days: check your data T_Celsius\n",
      "Warning datagap >= 5 days: check your data T_Celsius\n",
      "Warning datagap >= 5 days: check your data MinT_Celsius\n",
      "Warning datagap >= 5 days: check your data MinT_Celsius\n",
      "Warning datagap >= 5 days: check your data MaxT_Celsius\n",
      "Warning datagap >= 5 days: check your data MaxT_Celsius\n",
      "Warning datagap >= 5 days: check your data Precip_mm\n"
     ]
    }
   ],
   "source": [
    "#a/ Merge dataframes\n",
    "\n",
    "df3 = df2.append(df1, ignore_index=True)\n",
    "\n",
    "print(len(df3)) #Check nb of lines after merge -> should be close to 8760*2= 17,520\n",
    "\n",
    "#b/ Insert missing rows and drop rows outside year 2017\n",
    "\n",
    "df3 = df3.resample('60Min', on='valid_start').first().drop('valid_start', 1).reset_index()\n",
    "df4= df3.drop(df3[(df3.valid_start < \"2017-01-01 00:00:00\")|(df3.valid_start > \"2017-12-31 23:00:00\")].index)\n",
    "\n",
    "if (len(df4))!=8760:\n",
    "    print('Too many missing data, check your data')\n",
    "    \n",
    "print (df4.head()) #cross check data integrity\n",
    "print (df4.tail())\n",
    "\n",
    "#c/ Fill missing valid_end dates & station numbers\n",
    "\n",
    "df4['valid_end']=df4['valid_start']+ datetime.timedelta(0,3600)\n",
    "df4['station_number']=station\n",
    "\n",
    "#d/ Check number of missing values and change format of empty data so they can be addressed at e/\n",
    "\n",
    "print(len(df4))\n",
    "df4 = df4.replace('', np.nan, regex=True)\n",
    "print(df4.isna().sum())\n",
    "\n",
    "#e/ Create a warning line each time a period of at least 5 consecutive days without data is identified\n",
    "\n",
    "df4[\"T_Celsius\"] = df4[\"T_Celsius\"].apply(pd.to_numeric)\n",
    "df4[\"MinT_Celsius\"] = df4[\"MinT_Celsius\"].apply(pd.to_numeric)\n",
    "df4[\"MaxT_Celsius\"] = df4[\"MaxT_Celsius\"].apply(pd.to_numeric)\n",
    "df4[\"Precip_mm\"] = df4[\"Precip_mm\"].apply(pd.to_numeric)\n",
    "       \n",
    "Datagap(\"T_Celsius\",df4)\n",
    "Datagap(\"MinT_Celsius\",df4)\n",
    "Datagap(\"MaxT_Celsius\",df4)\n",
    "Datagap(\"Precip_mm\",df4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6 : Filling missing data and creating station csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_start       0\n",
      "valid_end         0\n",
      "station_number    0\n",
      "T_Celsius         0\n",
      "MinT_Celsius      0\n",
      "MaxT_Celsius      0\n",
      "Precip_mm         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#a/ Filling missing weather data based on x previous/following day(s)\n",
    "    \n",
    "Datafilling(\"T_Celsius\",df4)\n",
    "Datafilling(\"MinT_Celsius\",df4)\n",
    "Datafilling(\"MaxT_Celsius\",df4)\n",
    "Datafilling(\"Precip_mm\",df4)\n",
    "\n",
    "#b/ Final check and file export\n",
    "                                                   \n",
    "print(df4.isna().sum()) # Check nb of missing data\n",
    "    \n",
    "if (df4.isnull().values.any()):\n",
    "    print ('Warning: datagap for a given hour > 5 days: check your data') # Warning if too many missing data at a given hour.\n",
    "    \n",
    "df4=df4.round({'T_Celsius': 1,'MinT_Celsius':1,'MaxT_Celsius':1,'Precip_mm':1}) # Final cleaning of decimals.\n",
    "   \n",
    "station=str(station)\n",
    "df4.to_csv(r'csvfiles/weather2017_1H_'+station+'.csv',index=False)  # Export final csv file         \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
